{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ran within geoai-immap/notebooks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.integrate import trapz as integrate\n",
    "import itertools\n",
    "# source: https://en.wikipedia.org/wiki/File:Composite_trapezoidal_rule_illustration.png\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../utils')\n",
    "from model_utils import AREA_CODES, calculate_precision_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get results data to vm\n",
    "# !gsutil cp -r gs://immap-results/* results/\n",
    "# !gsutil cp -r gs://immap-training/20200509_dataset.csv ../data/20200509_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.87 s, sys: 2.05 s, total: 9.91 s\n",
      "Wall time: 9.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# grid-area mapping\n",
    "df = pd.read_csv('../data/20200509_dataset.csv')\n",
    "grid_area = (df[['uid', 'area']]\n",
    "             .drop_duplicates()\n",
    "             .sort_values('uid')\n",
    "             .rename(columns = {'uid': 'grid_id'}))\n",
    "assert grid_area[['grid_id']].drop_duplicates().shape[0] == grid_area.shape[0]\n",
    "\n",
    "# list of model strings per model type\n",
    "models = {\n",
    "    'logistic_regression': [\n",
    "        'penaltyl1_c0.001',\n",
    "        'penaltyl1_c0.010',\n",
    "        'penaltyl1_c0.100',\n",
    "        'penaltyl1_c1.000',\n",
    "        'penaltyl2_c0.001',\n",
    "        'penaltyl2_c0.010',\n",
    "        'penaltyl2_c0.100',\n",
    "        'penaltyl2_c1.000',\n",
    "    ], \n",
    "    'random_forest': [\n",
    "        'nestimators100_maxdepth5_minsamplessplit5_minsamplesleaf5',\n",
    "        'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1',\n",
    "        'nestimators300_maxdepth8_minsamplessplit5_minsamplesleaf5',\n",
    "        'nestimators800_maxdepth12_minsamplessplit15_minsamplesleaf2',\n",
    "        'nestimators800_maxdepth8_minsamplessplit2_minsamplesleaf10',\n",
    "    ],\n",
    "    'linear_svc': [\n",
    "        'c0.001',\n",
    "        'c0.010',\n",
    "        'c0.100',\n",
    "        'c1.000',\n",
    "    ],\n",
    "}\n",
    "\n",
    "neg_samplings = ['10k_results','30k_results','50k_results']\n",
    "\n",
    "model_types = list(models.keys())\n",
    "areas = list(AREA_CODES.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(neg_sample, model_type, model):\n",
    "    filedir = '../results/' + neg_sample + '/' + model_type + '_grid_preds_' + model + '.csv'\n",
    "    return pd.read_csv(filedir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model(muncity, model_type, neg_sample):\n",
    "    \"compares models using area under the curve\"\n",
    "    models_ = models[model_type]\n",
    "    sorted_aucs = []\n",
    "    for model in models_:\n",
    "        df = get_data(neg_sample, model_type, model)\n",
    "        df2 = pd.merge(df, grid_area, how = 'left')\n",
    "        area_code = [k for k,v in AREA_CODES.items() if v == muncity][0]\n",
    "        df3 = df2.query(\"area == \" + str(area_code))\n",
    "        series_ = calculate_precision_recall(df3)['recall'] # <-------specifies which curve to optimize\n",
    "        sorted_aucs.append(integrate(series_))\n",
    "    assert len(df) == len(df2)\n",
    "    assert len(df3) < len(df)\n",
    "    best_model = [models_[i] for i in range(len(models_)) if sorted_aucs[i] == max(sorted_aucs)][0]\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_membership(model1, model2, top = 0.1):\n",
    "    \"accepts 2 models, each defined as a tuple of 3 items: neg_sample, model_type, best_model\"\n",
    "    neg_sample1, model_type1, model1_ = model1\n",
    "    neg_sample2, model_type2, model2_ = model2\n",
    "    df1 = get_data(neg_sample1, model_type1, model1_)\n",
    "    df2 = get_data(neg_sample2, model_type2, model2_)\n",
    "    df1 = df1.sort_values('y_pred', ascending=False)\n",
    "    df2 = df2.sort_values('y_pred', ascending=False)\n",
    "    \n",
    "    # get top10%\n",
    "    df1_ = df1[0:int(df1.shape[0]*(0.1))]\n",
    "    df2_ = df2[0:int(df2.shape[0]*(0.1))]\n",
    "\n",
    "    # convert to set\n",
    "    set1 = set(list(df1_['grid_id']))\n",
    "    set2 = set(list(df2_['grid_id']))\n",
    "\n",
    "    return len(set1.intersection(set2)) / len(set1.union(set2)) #max(len(set1), len(set2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_matrix(muncity):\n",
    "    \"\"\"\n",
    "    Produce 9x9 matrix per municipality describing top10% membership intersections between models\n",
    "    \"\"\"\n",
    "    best_models = []\n",
    "    for neg_sample in neg_samplings:\n",
    "        for model_type in model_types:\n",
    "            models_ = models[model_type]\n",
    "            best_model = get_best_model(muncity, model_type, neg_sample)\n",
    "            best_models.append((neg_sample, model_type, best_model))\n",
    "    assert len(best_models) == 9\n",
    "    cart_prod = list(itertools.product(best_models, best_models))\n",
    "    assert len(cart_prod) == 81\n",
    "    pairs = []\n",
    "    for i in range(len(cart_prod)):\n",
    "        model1, model2 = cart_prod[i]\n",
    "        mem_int = intersect_membership(model1, model2, top = 0.1)\n",
    "        pairs.append((str(model1), str(model2), mem_int))\n",
    "    \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maicao',\n",
       " 'Riohacha',\n",
       " 'Uribia',\n",
       " 'Arauca',\n",
       " 'Cucuta',\n",
       " 'Tibu',\n",
       " 'Arauquita',\n",
       " 'Soacha',\n",
       " 'Bogota']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_v2(muncity):\n",
    "    \"compares models using area under the curve\"\n",
    "    models_2 = []\n",
    "    sorted_aucs = []\n",
    "    for neg_sample in neg_samplings:\n",
    "        for model_type in model_types:\n",
    "            models_ = models[model_type]\n",
    "            for model in models_:\n",
    "                df = get_data(neg_sample, model_type, model)\n",
    "                df2 = pd.merge(df, grid_area, how = 'left')\n",
    "                area_code = [k for k,v in AREA_CODES.items() if v == muncity][0]\n",
    "                df3 = df2.query(\"area == \" + str(area_code))\n",
    "                series_ = calculate_precision_recall(df3)['recall'] # <-------specifies which curve to optimize\n",
    "                models_2.append(model_type + '_' + model)\n",
    "                sorted_aucs.append(integrate(series_))\n",
    "    assert len(df) == len(df2)\n",
    "    assert len(df3) < len(df)\n",
    "    best_model, sorted_auc = [(models_2[i], sorted_aucs[i]) for i in range(len(models_2)) if sorted_aucs[i] == max(sorted_aucs)][0]\n",
    "    return best_model, sorted_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_sample = neg_samplings[0]\n",
    "model_type = model_types[1]\n",
    "model = models[model_type][1]\n",
    "muncity = 'Bogota'#'Arauquita'\n",
    "\n",
    "df = get_data(neg_sample, model_type, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.375"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_ = calculate_precision_recall(df)['recall'] # <-------specifies which curve to optimize\n",
    "integrate(series_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('logistic_regression_penaltyl1_c1.000', 92.5)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_model_v2('Bogota')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('random_forest_nestimators800_maxdepth12_minsamplessplit15_minsamplesleaf2',\n",
       " 87.64285714285714)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_model_v2('Arauca')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('logistic_regression_penaltyl1_c0.100', 94.5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_model_v2('Riohacha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 s, sys: 88.5 ms, total: 16.3 s\n",
      "Wall time: 16.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for area in areas:\n",
    "#     area = 'Maicao'\n",
    "    pairs = calc_matrix(area)\n",
    "    df = pd.DataFrame(pairs)\n",
    "    df.columns = ['model1', 'model2', 'intersection']\n",
    "    # df.sort_values('intersection')\n",
    "    # df.to_csv('pairs_' + area + '.csv')\n",
    "\n",
    "    # # convert to matrix\n",
    "    # df2 = pd.DataFrame(np.array(df['intersection']).reshape(9,9))\n",
    "    # names = list(df['model2'][0:9])\n",
    "    # df2.columns = names\n",
    "    # df2[area] = names\n",
    "    # df2.set_index(area, inplace = True)\n",
    "    # df2.to_csv('matrix_' + area + '.csv')\n",
    "\n",
    "    df['arch'] = ''\n",
    "    for i in range(len(df)):\n",
    "        row = df.iloc[i,:]\n",
    "        arch1 = row.model1.split(\"', '\")[1]\n",
    "        arch2 = row.model2.split(\"', '\")[1]\n",
    "        if arch1 == arch2:\n",
    "            df.loc[i,'arch'] = arch1\n",
    "        else:\n",
    "            df.loc[i,'arch'] = 'EXCLUDE'\n",
    "\n",
    "    with pd.ExcelWriter('matrixv2_' + area + '.xlsx') as writer:\n",
    "        for model_type in model_types:\n",
    "            # model_type = 'logistic_regression'\n",
    "            df_ = df.query(\"arch == '\" + model_type + \"'\")\n",
    "            df2 = pd.DataFrame(np.array(df_['intersection']).reshape(3,3))\n",
    "            names = list(df_['model2'][0:3])\n",
    "            df2.columns = names\n",
    "            df2[area] = names\n",
    "            df2.set_index(area, inplace = True)\n",
    "            # df2.to_csv('matrix_' + area + '_' + model_type + '.csv')\n",
    "            df2.to_excel(writer, sheet_name=area + '_' + model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compare to 03 optimization notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('10k_results', 'logistic_regression', 'penaltyl1_c0.100')</th>\n",
       "      <th>('10k_results', 'random_forest', 'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1')</th>\n",
       "      <th>('10k_results', 'linear_svc', 'c0.100')</th>\n",
       "      <th>('30k_results', 'logistic_regression', 'penaltyl1_c0.100')</th>\n",
       "      <th>('30k_results', 'random_forest', 'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1')</th>\n",
       "      <th>('30k_results', 'linear_svc', 'c0.100')</th>\n",
       "      <th>('50k_results', 'logistic_regression', 'penaltyl1_c0.010')</th>\n",
       "      <th>('50k_results', 'random_forest', 'nestimators800_maxdepth12_minsamplessplit15_minsamplesleaf2')</th>\n",
       "      <th>('50k_results', 'linear_svc', 'c0.010')</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Riohacha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>('10k_results', 'logistic_regression', 'penaltyl1_c0.100')</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('10k_results', 'random_forest', 'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1')</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('10k_results', 'linear_svc', 'c0.100')</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('30k_results', 'logistic_regression', 'penaltyl1_c0.100')</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('30k_results', 'random_forest', 'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1')</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('30k_results', 'linear_svc', 'c0.100')</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('50k_results', 'logistic_regression', 'penaltyl1_c0.010')</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.829787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('50k_results', 'random_forest', 'nestimators800_maxdepth12_minsamplessplit15_minsamplesleaf2')</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('50k_results', 'linear_svc', 'c0.010')</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ('10k_results', 'logistic_regression', 'penaltyl1_c0.100')  \\\n",
       "Riohacha                                                                                                         \n",
       "('10k_results', 'logistic_regression', 'penalty...                                           1.000000            \n",
       "('10k_results', 'random_forest', 'nestimators10...                                           0.409836            \n",
       "('10k_results', 'linear_svc', 'c0.100')                                                      0.869565            \n",
       "('30k_results', 'logistic_regression', 'penalty...                                           0.869565            \n",
       "('30k_results', 'random_forest', 'nestimators10...                                           0.482759            \n",
       "('30k_results', 'linear_svc', 'c0.100')                                                      0.755102            \n",
       "('50k_results', 'logistic_regression', 'penalty...                                           0.720000            \n",
       "('50k_results', 'random_forest', 'nestimators80...                                           0.433333            \n",
       "('50k_results', 'linear_svc', 'c0.010')                                                      0.720000            \n",
       "\n",
       "                                                    ('10k_results', 'random_forest', 'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1')  \\\n",
       "Riohacha                                                                                                                                             \n",
       "('10k_results', 'logistic_regression', 'penalty...                                           0.409836                                                \n",
       "('10k_results', 'random_forest', 'nestimators10...                                           1.000000                                                \n",
       "('10k_results', 'linear_svc', 'c0.100')                                                      0.433333                                                \n",
       "('30k_results', 'logistic_regression', 'penalty...                                           0.482759                                                \n",
       "('30k_results', 'random_forest', 'nestimators10...                                           0.869565                                                \n",
       "('30k_results', 'linear_svc', 'c0.100')                                                      0.508772                                                \n",
       "('50k_results', 'logistic_regression', 'penalty...                                           0.508772                                                \n",
       "('50k_results', 'random_forest', 'nestimators80...                                           0.829787                                                \n",
       "('50k_results', 'linear_svc', 'c0.010')                                                      0.535714                                                \n",
       "\n",
       "                                                    ('10k_results', 'linear_svc', 'c0.100')  \\\n",
       "Riohacha                                                                                      \n",
       "('10k_results', 'logistic_regression', 'penalty...                                 0.869565   \n",
       "('10k_results', 'random_forest', 'nestimators10...                                 0.433333   \n",
       "('10k_results', 'linear_svc', 'c0.100')                                            1.000000   \n",
       "('30k_results', 'logistic_regression', 'penalty...                                 0.829787   \n",
       "('30k_results', 'random_forest', 'nestimators10...                                 0.508772   \n",
       "('30k_results', 'linear_svc', 'c0.100')                                            0.791667   \n",
       "('50k_results', 'logistic_regression', 'penalty...                                 0.720000   \n",
       "('50k_results', 'random_forest', 'nestimators80...                                 0.457627   \n",
       "('50k_results', 'linear_svc', 'c0.010')                                            0.720000   \n",
       "\n",
       "                                                    ('30k_results', 'logistic_regression', 'penaltyl1_c0.100')  \\\n",
       "Riohacha                                                                                                         \n",
       "('10k_results', 'logistic_regression', 'penalty...                                           0.869565            \n",
       "('10k_results', 'random_forest', 'nestimators10...                                           0.482759            \n",
       "('10k_results', 'linear_svc', 'c0.100')                                                      0.829787            \n",
       "('30k_results', 'logistic_regression', 'penalty...                                           1.000000            \n",
       "('30k_results', 'random_forest', 'nestimators10...                                           0.508772            \n",
       "('30k_results', 'linear_svc', 'c0.100')                                                      0.755102            \n",
       "('50k_results', 'logistic_regression', 'penalty...                                           0.720000            \n",
       "('50k_results', 'random_forest', 'nestimators80...                                           0.457627            \n",
       "('50k_results', 'linear_svc', 'c0.010')                                                      0.720000            \n",
       "\n",
       "                                                    ('30k_results', 'random_forest', 'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1')  \\\n",
       "Riohacha                                                                                                                                             \n",
       "('10k_results', 'logistic_regression', 'penalty...                                           0.482759                                                \n",
       "('10k_results', 'random_forest', 'nestimators10...                                           0.869565                                                \n",
       "('10k_results', 'linear_svc', 'c0.100')                                                      0.508772                                                \n",
       "('30k_results', 'logistic_regression', 'penalty...                                           0.508772                                                \n",
       "('30k_results', 'random_forest', 'nestimators10...                                           1.000000                                                \n",
       "('30k_results', 'linear_svc', 'c0.100')                                                      0.563636                                                \n",
       "('50k_results', 'logistic_regression', 'penalty...                                           0.563636                                                \n",
       "('50k_results', 'random_forest', 'nestimators80...                                           0.791667                                                \n",
       "('50k_results', 'linear_svc', 'c0.010')                                                      0.592593                                                \n",
       "\n",
       "                                                    ('30k_results', 'linear_svc', 'c0.100')  \\\n",
       "Riohacha                                                                                      \n",
       "('10k_results', 'logistic_regression', 'penalty...                                 0.755102   \n",
       "('10k_results', 'random_forest', 'nestimators10...                                 0.508772   \n",
       "('10k_results', 'linear_svc', 'c0.100')                                            0.791667   \n",
       "('30k_results', 'logistic_regression', 'penalty...                                 0.755102   \n",
       "('30k_results', 'random_forest', 'nestimators10...                                 0.563636   \n",
       "('30k_results', 'linear_svc', 'c0.100')                                            1.000000   \n",
       "('50k_results', 'logistic_regression', 'penalty...                                 0.791667   \n",
       "('50k_results', 'random_forest', 'nestimators80...                                 0.482759   \n",
       "('50k_results', 'linear_svc', 'c0.010')                                            0.791667   \n",
       "\n",
       "                                                    ('50k_results', 'logistic_regression', 'penaltyl1_c0.010')  \\\n",
       "Riohacha                                                                                                         \n",
       "('10k_results', 'logistic_regression', 'penalty...                                           0.720000            \n",
       "('10k_results', 'random_forest', 'nestimators10...                                           0.508772            \n",
       "('10k_results', 'linear_svc', 'c0.100')                                                      0.720000            \n",
       "('30k_results', 'logistic_regression', 'penalty...                                           0.720000            \n",
       "('30k_results', 'random_forest', 'nestimators10...                                           0.563636            \n",
       "('30k_results', 'linear_svc', 'c0.100')                                                      0.791667            \n",
       "('50k_results', 'logistic_regression', 'penalty...                                           1.000000            \n",
       "('50k_results', 'random_forest', 'nestimators80...                                           0.482759            \n",
       "('50k_results', 'linear_svc', 'c0.010')                                                      0.829787            \n",
       "\n",
       "                                                    ('50k_results', 'random_forest', 'nestimators800_maxdepth12_minsamplessplit15_minsamplesleaf2')  \\\n",
       "Riohacha                                                                                                                                              \n",
       "('10k_results', 'logistic_regression', 'penalty...                                           0.433333                                                 \n",
       "('10k_results', 'random_forest', 'nestimators10...                                           0.829787                                                 \n",
       "('10k_results', 'linear_svc', 'c0.100')                                                      0.457627                                                 \n",
       "('30k_results', 'logistic_regression', 'penalty...                                           0.457627                                                 \n",
       "('30k_results', 'random_forest', 'nestimators10...                                           0.791667                                                 \n",
       "('30k_results', 'linear_svc', 'c0.100')                                                      0.482759                                                 \n",
       "('50k_results', 'logistic_regression', 'penalty...                                           0.482759                                                 \n",
       "('50k_results', 'random_forest', 'nestimators80...                                           1.000000                                                 \n",
       "('50k_results', 'linear_svc', 'c0.010')                                                      0.535714                                                 \n",
       "\n",
       "                                                    ('50k_results', 'linear_svc', 'c0.010')  \n",
       "Riohacha                                                                                     \n",
       "('10k_results', 'logistic_regression', 'penalty...                                 0.720000  \n",
       "('10k_results', 'random_forest', 'nestimators10...                                 0.535714  \n",
       "('10k_results', 'linear_svc', 'c0.100')                                            0.720000  \n",
       "('30k_results', 'logistic_regression', 'penalty...                                 0.720000  \n",
       "('30k_results', 'random_forest', 'nestimators10...                                 0.592593  \n",
       "('30k_results', 'linear_svc', 'c0.100')                                            0.791667  \n",
       "('50k_results', 'logistic_regression', 'penalty...                                 0.829787  \n",
       "('50k_results', 'random_forest', 'nestimators80...                                 0.535714  \n",
       "('50k_results', 'linear_svc', 'c0.010')                                            1.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for riohacha, 10K best logistic model should be L1_c0.1\n",
    "# PASS\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>('10k_results', 'logistic_regression', 'penaltyl1_c0.010')</th>\n",
       "      <th>('10k_results', 'random_forest', 'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1')</th>\n",
       "      <th>('10k_results', 'linear_svc', 'c0.010')</th>\n",
       "      <th>('30k_results', 'logistic_regression', 'penaltyl1_c0.010')</th>\n",
       "      <th>('30k_results', 'random_forest', 'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1')</th>\n",
       "      <th>('30k_results', 'linear_svc', 'c0.010')</th>\n",
       "      <th>('50k_results', 'logistic_regression', 'penaltyl1_c0.010')</th>\n",
       "      <th>('50k_results', 'random_forest', 'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1')</th>\n",
       "      <th>('50k_results', 'linear_svc', 'c0.010')</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soacha</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>('10k_results', 'logistic_regression', 'penaltyl1_c0.010')</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.829787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('10k_results', 'random_forest', 'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1')</td>\n",
       "      <td>0.457627</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('10k_results', 'linear_svc', 'c0.010')</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('30k_results', 'logistic_regression', 'penaltyl1_c0.010')</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.829787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('30k_results', 'random_forest', 'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1')</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.592593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('30k_results', 'linear_svc', 'c0.010')</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.911111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('50k_results', 'logistic_regression', 'penaltyl1_c0.010')</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.829787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('50k_results', 'random_forest', 'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1')</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>('50k_results', 'linear_svc', 'c0.010')</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ('10k_results', 'logistic_regression', 'penaltyl1_c0.010')  \\\n",
       "Soacha                                                                                                           \n",
       "('10k_results', 'logistic_regression', 'penalty...                                           1.000000            \n",
       "('10k_results', 'random_forest', 'nestimators10...                                           0.457627            \n",
       "('10k_results', 'linear_svc', 'c0.010')                                                      0.791667            \n",
       "('30k_results', 'logistic_regression', 'penalty...                                           0.869565            \n",
       "('30k_results', 'random_forest', 'nestimators10...                                           0.508772            \n",
       "('30k_results', 'linear_svc', 'c0.010')                                                      0.829787            \n",
       "('50k_results', 'logistic_regression', 'penalty...                                           0.869565            \n",
       "('50k_results', 'random_forest', 'nestimators10...                                           0.535714            \n",
       "('50k_results', 'linear_svc', 'c0.010')                                                      0.829787            \n",
       "\n",
       "                                                    ('10k_results', 'random_forest', 'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1')  \\\n",
       "Soacha                                                                                                                                               \n",
       "('10k_results', 'logistic_regression', 'penalty...                                           0.457627                                                \n",
       "('10k_results', 'random_forest', 'nestimators10...                                           1.000000                                                \n",
       "('10k_results', 'linear_svc', 'c0.010')                                                      0.535714                                                \n",
       "('30k_results', 'logistic_regression', 'penalty...                                           0.482759                                                \n",
       "('30k_results', 'random_forest', 'nestimators10...                                           0.869565                                                \n",
       "('30k_results', 'linear_svc', 'c0.010')                                                      0.563636                                                \n",
       "('50k_results', 'logistic_regression', 'penalty...                                           0.508772                                                \n",
       "('50k_results', 'random_forest', 'nestimators10...                                           0.869565                                                \n",
       "('50k_results', 'linear_svc', 'c0.010')                                                      0.535714                                                \n",
       "\n",
       "                                                    ('10k_results', 'linear_svc', 'c0.010')  \\\n",
       "Soacha                                                                                        \n",
       "('10k_results', 'logistic_regression', 'penalty...                                 0.791667   \n",
       "('10k_results', 'random_forest', 'nestimators10...                                 0.535714   \n",
       "('10k_results', 'linear_svc', 'c0.010')                                            1.000000   \n",
       "('30k_results', 'logistic_regression', 'penalty...                                 0.755102   \n",
       "('30k_results', 'random_forest', 'nestimators10...                                 0.592593   \n",
       "('30k_results', 'linear_svc', 'c0.010')                                            0.869565   \n",
       "('50k_results', 'logistic_regression', 'penalty...                                 0.791667   \n",
       "('50k_results', 'random_forest', 'nestimators10...                                 0.622642   \n",
       "('50k_results', 'linear_svc', 'c0.010')                                            0.791667   \n",
       "\n",
       "                                                    ('30k_results', 'logistic_regression', 'penaltyl1_c0.010')  \\\n",
       "Soacha                                                                                                           \n",
       "('10k_results', 'logistic_regression', 'penalty...                                           0.869565            \n",
       "('10k_results', 'random_forest', 'nestimators10...                                           0.482759            \n",
       "('10k_results', 'linear_svc', 'c0.010')                                                      0.755102            \n",
       "('30k_results', 'logistic_regression', 'penalty...                                           1.000000            \n",
       "('30k_results', 'random_forest', 'nestimators10...                                           0.535714            \n",
       "('30k_results', 'linear_svc', 'c0.010')                                                      0.829787            \n",
       "('50k_results', 'logistic_regression', 'penalty...                                           0.954545            \n",
       "('50k_results', 'random_forest', 'nestimators10...                                           0.563636            \n",
       "('50k_results', 'linear_svc', 'c0.010')                                                      0.829787            \n",
       "\n",
       "                                                    ('30k_results', 'random_forest', 'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1')  \\\n",
       "Soacha                                                                                                                                               \n",
       "('10k_results', 'logistic_regression', 'penalty...                                           0.508772                                                \n",
       "('10k_results', 'random_forest', 'nestimators10...                                           0.869565                                                \n",
       "('10k_results', 'linear_svc', 'c0.010')                                                      0.592593                                                \n",
       "('30k_results', 'logistic_regression', 'penalty...                                           0.535714                                                \n",
       "('30k_results', 'random_forest', 'nestimators10...                                           1.000000                                                \n",
       "('30k_results', 'linear_svc', 'c0.010')                                                      0.622642                                                \n",
       "('50k_results', 'logistic_regression', 'penalty...                                           0.563636                                                \n",
       "('50k_results', 'random_forest', 'nestimators10...                                           0.869565                                                \n",
       "('50k_results', 'linear_svc', 'c0.010')                                                      0.592593                                                \n",
       "\n",
       "                                                    ('30k_results', 'linear_svc', 'c0.010')  \\\n",
       "Soacha                                                                                        \n",
       "('10k_results', 'logistic_regression', 'penalty...                                 0.829787   \n",
       "('10k_results', 'random_forest', 'nestimators10...                                 0.563636   \n",
       "('10k_results', 'linear_svc', 'c0.010')                                            0.869565   \n",
       "('30k_results', 'logistic_regression', 'penalty...                                 0.829787   \n",
       "('30k_results', 'random_forest', 'nestimators10...                                 0.622642   \n",
       "('30k_results', 'linear_svc', 'c0.010')                                            1.000000   \n",
       "('50k_results', 'logistic_regression', 'penalty...                                 0.869565   \n",
       "('50k_results', 'random_forest', 'nestimators10...                                 0.653846   \n",
       "('50k_results', 'linear_svc', 'c0.010')                                            0.911111   \n",
       "\n",
       "                                                    ('50k_results', 'logistic_regression', 'penaltyl1_c0.010')  \\\n",
       "Soacha                                                                                                           \n",
       "('10k_results', 'logistic_regression', 'penalty...                                           0.869565            \n",
       "('10k_results', 'random_forest', 'nestimators10...                                           0.508772            \n",
       "('10k_results', 'linear_svc', 'c0.010')                                                      0.791667            \n",
       "('30k_results', 'logistic_regression', 'penalty...                                           0.954545            \n",
       "('30k_results', 'random_forest', 'nestimators10...                                           0.563636            \n",
       "('30k_results', 'linear_svc', 'c0.010')                                                      0.869565            \n",
       "('50k_results', 'logistic_regression', 'penalty...                                           1.000000            \n",
       "('50k_results', 'random_forest', 'nestimators10...                                           0.592593            \n",
       "('50k_results', 'linear_svc', 'c0.010')                                                      0.829787            \n",
       "\n",
       "                                                    ('50k_results', 'random_forest', 'nestimators100_maxdepth8_minsamplessplit15_minsamplesleaf1')  \\\n",
       "Soacha                                                                                                                                               \n",
       "('10k_results', 'logistic_regression', 'penalty...                                           0.535714                                                \n",
       "('10k_results', 'random_forest', 'nestimators10...                                           0.869565                                                \n",
       "('10k_results', 'linear_svc', 'c0.010')                                                      0.622642                                                \n",
       "('30k_results', 'logistic_regression', 'penalty...                                           0.563636                                                \n",
       "('30k_results', 'random_forest', 'nestimators10...                                           0.869565                                                \n",
       "('30k_results', 'linear_svc', 'c0.010')                                                      0.653846                                                \n",
       "('50k_results', 'logistic_regression', 'penalty...                                           0.592593                                                \n",
       "('50k_results', 'random_forest', 'nestimators10...                                           1.000000                                                \n",
       "('50k_results', 'linear_svc', 'c0.010')                                                      0.622642                                                \n",
       "\n",
       "                                                    ('50k_results', 'linear_svc', 'c0.010')  \n",
       "Soacha                                                                                       \n",
       "('10k_results', 'logistic_regression', 'penalty...                                 0.829787  \n",
       "('10k_results', 'random_forest', 'nestimators10...                                 0.535714  \n",
       "('10k_results', 'linear_svc', 'c0.010')                                            0.791667  \n",
       "('30k_results', 'logistic_regression', 'penalty...                                 0.829787  \n",
       "('30k_results', 'random_forest', 'nestimators10...                                 0.592593  \n",
       "('30k_results', 'linear_svc', 'c0.010')                                            0.911111  \n",
       "('50k_results', 'logistic_regression', 'penalty...                                 0.829787  \n",
       "('50k_results', 'random_forest', 'nestimators10...                                 0.622642  \n",
       "('50k_results', 'linear_svc', 'c0.010')                                            1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for soacha, 30K best svc model should be c0.01\n",
    "# FAIL\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['c0.001', 'c0.010', 'c0.100', 'c1.000'], [84.5, 87.5, 87.5, 87.5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# displayed best, c0.01, is same as c1.00 as recorded in notebook\n",
    "def get_models(muncity, model_type, neg_sample):\n",
    "    \"compares models using area under the curve\"\n",
    "    models_ = models[model_type]\n",
    "    sorted_aucs = []\n",
    "    for model in models_:\n",
    "        df = get_data(neg_sample, model_type, model)\n",
    "        df2 = pd.merge(df, grid_area, how = 'left')\n",
    "        area_code = [k for k,v in AREA_CODES.items() if v == muncity][0]\n",
    "        df3 = df2.query(\"area == \" + str(area_code))\n",
    "        series_ = calculate_precision_recall(df3)['recall'] # <-------specifies which curve to optimize\n",
    "        sorted_aucs.append(integrate(series_))\n",
    "    assert len(df) == len(df2)\n",
    "    assert len(df3) < len(df)\n",
    "    # best_model = [models_[i] for i in range(len(models_)) if sorted_aucs[i] == max(sorted_aucs)][0]\n",
    "    return models_, sorted_aucs\n",
    "\n",
    "get_models('Soacha', 'linear_svc', '30k_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test 1\n",
    "# neg_sample = neg_samplings[0]\n",
    "# model_type = model_types[1]\n",
    "# model = models[model_type][1]\n",
    "# muncity = 'Maicao'#'Arauquita'\n",
    "\n",
    "# df = get_data(neg_sample, model_type, model)\n",
    "# df2 = pd.merge(df, grid_area, how = 'left')\n",
    "# area_code = [k for k,v in AREA_CODES.items() if v == muncity][0]\n",
    "# df3 = df2.query(\"area == \" + str(area_code))\n",
    "\n",
    "# df3.head(3).sort_values('y_pred', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
